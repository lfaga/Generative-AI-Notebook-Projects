{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2gwCJ8f3mjA"
   },
   "source": [
    "# **WAN Fusion X IMAGE TO VIDEO WITH FAST Q3 GGUF MODEL**\n",
    "- QuantStack/Wan2.1_I2V_14B_FusionX-GGUF\n",
    "- The videos are generated at 16fps. You can use the `Frame Interpolation` notebook in this github repository (https://github.com/Isi-dev/Google-Colab_Notebooks) to increase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t089iwSddWDL"
   },
   "outputs": [],
   "source": [
    "# @title Prepare Environment\n",
    "import sys, os\n",
    "\n",
    "!pip install --upgrade --quiet torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q torchsde einops diffusers accelerate xformers\n",
    "!pip install av\n",
    "\n",
    "!apt -y install -qq aria2 ffmpeg\n",
    "\n",
    "# 1. Clone the OFFICIAL ComfyUI repository for maximum stability\n",
    "!git clone https://github.com/comfyanonymous/ComfyUI.git /content/ComfyUI\n",
    "!pip install -r /content/ComfyUI/requirements.txt\n",
    "\n",
    "# 2. Install the community-recommended GGUF custom node from city96\n",
    "!git clone https://github.com/city96/ComfyUI-GGUF.git /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
    "!pip install -r /content/ComfyUI/custom_nodes/ComfyUI_GGUF/requirements.txt\n",
    "\n",
    "\n",
    "model_name = \"Wan2.1_T2V_14B_FusionX-Q3_K_L.gguf\"\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/QuantStack/Wan2.1_T2V_14B_FusionX-GGUF/resolve/main/{model_name} -d /content/ComfyUI/models/unet -o {model_name}\n",
    "\n",
    "encoder_name = \"umt5_xxl_fp8_e4m3fn_scaled.safetensors\"\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/{encoder_name} -d /content/ComfyUI/models/text_encoders -o {encoder_name}\n",
    "#encoder_name = \"umt5-xxl-encoder-Q8_0.gguf\"\n",
    "#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/city96/umt5-xxl-encoder-gguf/resolve/main/{encoder_name} -d /content/ComfyUI/models/text_encoders -o {encoder_name}\n",
    "\n",
    "vae_name = \"wan_2.1_vae.safetensors\"\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/{vae_name} -d /content/ComfyUI/models/vae -o {vae_name}\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "sys.path.insert(0, '/content/ComfyUI')\n",
    "\n",
    "print(\"✅ Environment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_DY1SGSH947"
   },
   "outputs": [],
   "source": [
    "# @title LoRAs Config\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "!mkdir -p /content/ComfyUI/models/loras\n",
    "\n",
    "lora_file_root = \"/content/drive/MyDrive/AI/LoRAs/Wan2.1\"\n",
    "\n",
    "loras_config = [\n",
    "  {\n",
    "    \"filename\": \"sample-wan-lora.safetensors\",\n",
    "    \"strength\": 1.0\n",
    "  }\n",
    "]\n",
    "\n",
    "for lora_config in loras_config:\n",
    "  lora_filename = lora_config[\"filename\"]\n",
    "  !cp \"{lora_file_root}/{lora_filename}\" \"/content/ComfyUI/models/loras/\"\n",
    "\n",
    "print(\"✅ LoRAs Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_fxP0vq1gRu"
   },
   "outputs": [],
   "source": [
    "# @title Logic\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, random, pdb\n",
    "import imageio\n",
    "from IPython.display import display, Video as IPVideo, Image as IPImage\n",
    "\n",
    "from comfy import model_management\n",
    "\n",
    "from nodes import (\n",
    "    CLIPTextEncode,\n",
    "    VAEDecode,\n",
    "    VAELoader,\n",
    "    KSampler,\n",
    "    LoraLoader\n",
    ")\n",
    "\n",
    "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF, CLIPLoaderGGUF\n",
    "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
    "from comfy_extras.nodes_hunyuan import EmptyHunyuanLatentVideo\n",
    "\n",
    "def clear_memory():\n",
    "\n",
    "    model_management.unload_all_models()\n",
    "\n",
    "    gc.collect()\n",
    "    for obj in list(globals().values()):\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
    "            del obj\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "def save_as_mp4(images, filename_prefix, fps, crf=16, preset='slow', output_dir=\"/content/ComfyUI/output\"):\n",
    "    \"\"\"\n",
    "    Save images as a high-quality H.265 MP4 video using imageio and ffmpeg.\n",
    "\n",
    "    Args:\n",
    "        images: A list of PyTorch tensors (frames).\n",
    "        filename_prefix: The base name for the output file.\n",
    "        fps: Frames per second for the video.\n",
    "        crf: Constant Rate Factor for quality (lower is better, 16 is high quality).\n",
    "        preset: Encoding speed vs. compression (e.g., 'ultrafast', 'medium', 'slow').\n",
    "        output_dir: The directory to save the video in.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
    "\n",
    "    # Convert tensors to NumPy arrays in the correct format\n",
    "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
    "\n",
    "    # Define the ffmpeg parameters for high-quality H.265\n",
    "    writer_kwargs = {\n",
    "        'format': 'FFMPEG',          # Explicitly use the FFMPEG backend\n",
    "        'mode': 'I',                 # 'I' for a sequence of images\n",
    "        'fps': int(fps),\n",
    "        'codec': 'libx265',          # H.265 codec\n",
    "        'output_params': [\n",
    "            '-preset', str(preset),  # Encoding preset\n",
    "            '-crf', str(int(crf)),   # Constant Rate Factor for quality\n",
    "            '-pix_fmt', 'yuv420p'    # Pixel format for compatibility\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    print(f\"Saving high-quality MP4 to: {output_path}\")\n",
    "    with imageio.get_writer(output_path, **writer_kwargs) as writer:\n",
    "        for frame in frames:\n",
    "            writer.append_data(frame)\n",
    "\n",
    "    print(\"Video saved successfully.\")\n",
    "    return output_path\n",
    "\n",
    "def save_as_image_sequence(images, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
    "    \"\"\"Save sequence of frames as PNG image.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    ret_array = []\n",
    "\n",
    "    for idx, image in enumerate(images, start=1):\n",
    "      output_path = f\"{output_dir}/{filename_prefix}_{idx:04d}.png\"\n",
    "      ret_array.append(output_path)\n",
    "      frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
    "      Image.fromarray(frame).save(output_path)\n",
    "\n",
    "    return ret_array\n",
    "\n",
    "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
    "    \"\"\"Save single frame as PNG image.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
    "\n",
    "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    Image.fromarray(frame).save(output_path)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "def generate_video(\n",
    "    positive_prompt: str = \"a cute cat playing with a ball of yarn\",\n",
    "    negative_prompt: str = (\"overexposed, blurred details, subtitles, \"\n",
    "       \"desaturated, low contrast, washed out, dull colors, flat lighting, \"\n",
    "       \"worst quality, low quality, JPEG compression artifacts, \"\n",
    "       \"incomplete, extra fingers, poorly drawn hands, poorly drawn faces, \"\n",
    "       \"deformed, disfigured, misshapen limbs, fused fingers, still picture, \"\n",
    "       \"three legs, walking backwards, watermark, text, signature\"),\n",
    "    width: int = 832,\n",
    "    height: int = 480,\n",
    "    seed: int = 82628696717253,\n",
    "    steps: int = 4,\n",
    "    cfg_scale: float = 1.0,\n",
    "    sampler_name: str = \"uni_pc\",\n",
    "    scheduler: str = \"simple\",\n",
    "    frames: int = 33,\n",
    "    fps: int = 16,\n",
    "    output_format: str = \"mp4\"\n",
    "):\n",
    "\n",
    "  with torch.inference_mode():\n",
    "\n",
    "      print(f\"Loading...{encoder_name}\")\n",
    "      text_encoder = CLIPLoader().load_clip(encoder_name, \"wan\")[0]\n",
    "      print(f\"Loading...{model_name}\")\n",
    "      model = UnetLoaderGGUF().load_unet(model_name)[0]\n",
    "\n",
    "      for lora_config in loras_config:\n",
    "\n",
    "        lora_name = lora_config.get(\"filename\")\n",
    "        strength = float(lora_config.get(\"strength\", 1.0))\n",
    "\n",
    "        print(f\"Applying LoRA '{lora_name}'\")\n",
    "        patched_model, patched_clip = LoraLoader().load_lora(\n",
    "            model = model,\n",
    "            clip = text_encoder,\n",
    "            lora_name = lora_name,\n",
    "            strength_model = strength,\n",
    "            strength_clip = strength\n",
    "        )\n",
    "        if strength > 0.0:\n",
    "          #load_lora clones model and clip when strenght > 0.0\n",
    "          del model, text_encoder\n",
    "        model = patched_model\n",
    "        text_encoder = patched_clip\n",
    "\n",
    "      positive = CLIPTextEncode().encode(text_encoder, positive_prompt)[0]\n",
    "      negative = CLIPTextEncode().encode(text_encoder, negative_prompt)[0]\n",
    "\n",
    "      #pdb.set_trace() #for checking VRAM usage at this point\n",
    "\n",
    "      del text_encoder\n",
    "\n",
    "      empty_latent_video = EmptyHunyuanLatentVideo().generate(\n",
    "          width, height, frames, batch_size=1)[0]\n",
    "\n",
    "      print(f\"Loading...{vae_name}\")\n",
    "      vae = VAELoader().load_vae(vae_name)[0]\n",
    "\n",
    "      final_model = ModelSamplingSD3().patch(model, 8.0)[0]\n",
    "\n",
    "      del model\n",
    "\n",
    "      #pdb.set_trace() #for checking VRAM usage at this point\n",
    "\n",
    "      print(f\"Sampling...\")\n",
    "      sampled = KSampler().sample(\n",
    "          model=final_model,\n",
    "          seed=seed,\n",
    "          steps=steps,\n",
    "          cfg=cfg_scale,\n",
    "          sampler_name=sampler_name,\n",
    "          scheduler=scheduler,\n",
    "          positive=positive,\n",
    "          negative=negative,\n",
    "          latent_image=empty_latent_video\n",
    "      )[0]\n",
    "\n",
    "      del positive, negative\n",
    "      del final_model\n",
    "\n",
    "      decoded = VAEDecode().decode(vae, sampled)[0]\n",
    "\n",
    "      if frames == 1:\n",
    "          output_path = save_as_image(decoded[0], \"ComfyUI\")\n",
    "          display(IPImage(filename=output_path))\n",
    "      else:\n",
    "          if output_format.lower() == \"mp4\":\n",
    "              output_path = save_as_mp4(decoded, \"ComfyUI\", fps)\n",
    "              display(IPVideo(output_path, embed=True))\n",
    "          else: # Defaulting to image sequence\n",
    "              output_images = save_as_image_sequence(decoded, \"ComfyUI\")\n",
    "              display(IPImage(filename=output_images[0]))\n",
    "\n",
    "      del vae, decoded\n",
    "      clear_memory()\n",
    "\n",
    "print(\"✅ Logic Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wo8w6tKerJMJ"
   },
   "outputs": [],
   "source": [
    "# @title Generate Video\n",
    "\n",
    "positive_prompt = \"a black kitten playing with a ball of yarn\" # @param {\"type\":\"string\"}\n",
    "negative_prompt = \"overexposed, blurred details, subtitles, worst quality, low quality, JPEG compression artifacts, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, fused fingers, still picture, three legs, walking backwards, watermark, text, signature\" # @param {\"type\":\"string\"}\n",
    "width = 480 # @param {\"type\":\"number\"}\n",
    "height = 832 # @param {\"type\":\"number\"}\n",
    "seed = 42 # @param {\"type\":\"integer\"}\n",
    "steps = 4 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
    "cfg_scale = 1.0 # @param {\"type\":\"number\", \"min\":1, \"max\":20}\n",
    "sampler_name = \"uni_pc\" # @param [\"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
    "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
    "frames = 33 # @param {\"type\":\"integer\", \"min\":1, \"max\":121}\n",
    "fps = 12 # @param {\"type\":\"integer\", \"min\":1, \"max\":60}\n",
    "output_format = \"mp4\" # @param [\"mp4\", \"image_sequence\"]\n",
    "\n",
    "import random\n",
    "seed = seed if seed else random.randint(0, 2**32 - 1)\n",
    "print(f\"Using seed: {seed}\")\n",
    "\n",
    "generate_video(\n",
    "    positive_prompt=positive_prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    seed=seed,\n",
    "    steps=steps,\n",
    "    cfg_scale=cfg_scale,\n",
    "    sampler_name=sampler_name,\n",
    "    scheduler=scheduler,\n",
    "    frames=frames,\n",
    "    fps=fps,\n",
    "    output_format=output_format\n",
    ")\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0yKqpf78AlbC"
   },
   "outputs": [],
   "source": [
    "# @title Clear Memory in case of stopping execution\n",
    "clear_memory()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_14B_I2V_GGUF_Free.ipynb",
     "timestamp": 1748249329096
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
